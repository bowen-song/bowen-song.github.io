<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Bowen Song" />
    
    <link rel="shortcut icon" type="image/x-icon" href="/img/favicon.ico">
    <title>Project 2: Modeling, Testing, and Predicting</title>
    <meta name="generator" content="Hugo 0.83.1" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="/css/main.css" />
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,400,200bold,400old" />
    
    <!--[if lt IE 9]>
			<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
			<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
		<![endif]-->

    
  </head>

  <body>
    <div id="wrap">
      
      <nav class="navbar navbar-default">
  <div class="container">
    <div class="navbar-header">
      <a class="navbar-brand" href="/"><i class="fa fa-home"></i></a>
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <div class="navbar-collapse collapse" id="navbar">
      <ul class="nav navbar-nav navbar-right">
      
        
        <li><a href="/post/">BLOG</a></li>
        
        <li><a href="/projects/">PROJECTS</a></li>
        
        <li><a href="/resume.pdf">RESUME</a></li>
        
      
      </ul>
    </div>
  </div>
</nav>

      <div class="container">
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <div class="blog-post">
          <h3>
            <strong><a href="/project/project2/">Project 2: Modeling, Testing, and Predicting</a></strong>
          </h3>
        </div>
 
<div class="blog-title">
          <h4>
         November 24, 2020 
            &nbsp;&nbsp;
            
          </h4>
        </div>

        <div class="panel panel-default">
          <div class="panel-body">
            <div class="blogpost">
              
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>


<hr />
<div id="setting-up" class="section level3">
<h3>Setting Up</h3>
<pre class="r"><code># all data sources linked at the end election results by
# county
elect_untidy &lt;- read_csv(&quot;presidential.csv&quot;)

# COVID-19 by county
cvd_untidy &lt;- read_csv(&quot;us-counties2.csv&quot;)

# mask use by county
mask_untidy &lt;- read_csv(&quot;mask-use-by-county2.csv&quot;)

# educational attainment by county data should discretized
# into dominant educational level by county
education_untidy &lt;- read_csv(&quot;Education.csv&quot;)

# population data by county
popdata_untidy &lt;- read_csv(&quot;PopulationEstimates.csv&quot;)

# poverty estimates by county
povdata_untidy &lt;- read_csv(&quot;PovertyEstimates.csv&quot;)

# unemployment data and household income estimates by county
unemp_untidy &lt;- read_csv(&quot;Unemployment.csv&quot;)</code></pre>
<hr />
</div>
<div id="introduction" class="section level3">
<h3>Introduction</h3>
<p>A number of the datasets I have chosen for this project contain extraneous variables that will be removed while tidying the datasets as needed.</p>
<ul>
<li><p>The <code>cvd</code> dataset is US COVID-19 data organized by county collected by the NY Times. <code>cvd</code> contains 6 variables that will all be kept: <code>date</code>, <code>county</code>, <code>state</code>, <code>fips</code> (every county’s unique numerical identifier), <code>cases</code> (cases of COVID-19), and <code>deaths</code> (deaths to COVID-19). For this project, only the information from 11-19-2020 will be kept, as that date provides the most up-to-date COVID-19 data (as of starting the project).</p></li>
<li><p>The <code>elect</code> dataset contains county-level data on the results of the 2020 presidential election and is provided by the NY Times. Of the 106 original variables, only 4 are kept: <code>fips</code>, <code>votes</code>, <code>results_trumpd</code>, <code>results_bidenj</code>, and <code>trumpwin</code> (binary variable where 1 = win for Trump, 0 = win for Biden).</p></li>
<li><p>The <code>mask</code> dataset contains the proportion of people by <code>COUNTYFP</code> (county fips) who <code>always_mask</code>, <code>freq_mask</code>, <code>sometimes_mask</code>, <code>rarely_mask</code>, and <code>never_mask</code> when they could encounter people, and is provided by a survey conducted by Dynata for the NY Times.</p></li>
<li><p>The <code>education</code> dataset contains county-level information on the educational attainment for adults 25+ and is based on the 2014-18 American Community Survey. Of the original 47 variables, 6 are kept: <code>fips</code>, <code>PrimaryEdAttained</code> (a discretized variable reporting the primary education level attained by county), and <code>lessthanHS</code>, <code>HSonly</code>, <code>someCollegeorAssoc</code>, <code>Bachorgreater</code>, which are numeric counts of the number of people in each county with an educational attainment of less than high school, high school only, some college/associate degree, or a bachelor’s or higher.</p></li>
<li><p>The <code>popdata</code> dataset contains county-level data on population and is provided by the Economic Research Service of the US Department of Agriculture. Of the original 166 variables, 5 are kept: <code>fips</code>, <code>pop2019</code>, <code>int_mig</code> (international migration), <code>dom_mig</code> (domestic migration), and <code>net_mig</code> (net migration).</p></li>
<li><p>The <code>povdata</code> dataset contains county-level information on different poverty metrics and is sourced from the US Census Bureau and Small Area Income and Poverty Estimates (SAIPE) Program. Of the original 34 variables, 2 are kept: <code>fips</code> and <code>pctpov</code> (the percent in poverty in 2018).</p></li>
<li><p>The <code>unemp</code> dataset contains county-level information on employment data and median household income and is provided by the Economic Research Service of the US Department of Agriculture. Of the original 88 variables, 4 are kept: <code>fips</code>, <code>emp</code> (employment counts), <code>unemp</code> (unemployment counts), <code>med_inc</code> (median household income).</p></li>
</ul>
<p>Regardless of which side of the political spectrum you stand on, I think it’s fair to say that the 2020 presidential election was one for the history books. With that in mind, I plan to use the above data to determine if there was any method to the madness; county-by-county (all 3000+), I’m hoping this project can lead us to a better understanding of what may have swung the election to a Biden victory. Off the bat, I am expecting to see that counties more heavily impacted by COVID-19 to lean Biden - Trump has been vocally callous in his response to COVID-19 and I’m expecting this to turn some away from him. In addition, I am expecting counties with higher proportions of people who <code>always_mask</code> lean Biden; Trump has actively downplayed the efficacy of masks since the onset of the pandemic and as such, I’m expecting this to be a potential indicator of the county’s preference for Trump. It’s worth noting that with issues as complicated as these, it’s very difficult to draw any meaningful conclusions, and even if the tests run in this project show significant effects, there may still be additional confounding variables worth considering. Let’s get into it!</p>
<hr />
</div>
<div id="tidying-datasets" class="section level3">
<h3>Tidying Datasets</h3>
<p>Cleaning <code>cvd</code>:</p>
<pre class="r"><code># filtering most up-to-date COVID-19 data
cvd &lt;- cvd_untidy %&gt;% filter(date == as.Date(&quot;2020-11-19&quot;))

glimpse(cvd)</code></pre>
<pre><code>## Rows: 3,247
## Columns: 6
## $ date   &lt;date&gt; 2020-11-19, 2020-11-19, 2020-11-19, 2020-11-19, 2020-11-19, 2…
## $ county &lt;chr&gt; &quot;Autauga&quot;, &quot;Baldwin&quot;, &quot;Barbour&quot;, &quot;Bibb&quot;, &quot;Blount&quot;, &quot;Bullock&quot;, …
## $ state  &lt;chr&gt; &quot;Alabama&quot;, &quot;Alabama&quot;, &quot;Alabama&quot;, &quot;Alabama&quot;, &quot;Alabama&quot;, &quot;Alabam…
## $ fips   &lt;chr&gt; &quot;01001&quot;, &quot;01003&quot;, &quot;01005&quot;, &quot;01007&quot;, &quot;01009&quot;, &quot;01011&quot;, &quot;01013&quot;,…
## $ cases  &lt;dbl&gt; 2554, 7933, 1145, 1011, 2683, 680, 1113, 5814, 1641, 956, 2122…
## $ deaths &lt;dbl&gt; 39, 84, 10, 18, 35, 19, 41, 111, 48, 24, 36, 12, 19, 23, 14, 1…</code></pre>
<p>Cleaning <code>elect</code>:</p>
<pre class="r"><code>elect &lt;- elect_untidy %&gt;% group_by(fips) %&gt;% summarize_if(is.numeric, 
    sum, na.rm = T) %&gt;% select(fips, votes, results_trumpd, results_bidenj) %&gt;% 
    # plurality cut out other candidates because none of them
# compete with trump/biden for plurality
mutate(trumpwin = ifelse(results_trumpd/votes &gt; results_bidenj/votes, 
    1, 0))

glimpse(elect)</code></pre>
<pre><code>## Rows: 3,159
## Columns: 5
## $ fips           &lt;chr&gt; &quot;01001&quot;, &quot;01003&quot;, &quot;01005&quot;, &quot;01007&quot;, &quot;01009&quot;, &quot;01011&quot;, …
## $ votes          &lt;dbl&gt; 27639, 108945, 10457, 9573, 27459, 4603, 9466, 50743, …
## $ results_trumpd &lt;dbl&gt; 19764, 83055, 5605, 7508, 24595, 1143, 5448, 34964, 87…
## $ results_bidenj &lt;dbl&gt; 7450, 24344, 4772, 1982, 2627, 3439, 3953, 15118, 6356…
## $ trumpwin       &lt;dbl&gt; 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …</code></pre>
<p>Cleaning <code>mask</code>:</p>
<pre class="r"><code>mask &lt;- mask_untidy %&gt;% # renaming variables for clarity
rename(never_mask = NEVER, rarely_mask = RARELY, sometimes_mask = SOMETIMES, 
    freq_mask = FREQUENTLY, always_mask = ALWAYS, fips = COUNTYFP)

glimpse(mask)</code></pre>
<pre><code>## Rows: 3,142
## Columns: 6
## $ fips           &lt;chr&gt; &quot;01001&quot;, &quot;01003&quot;, &quot;01005&quot;, &quot;01007&quot;, &quot;01009&quot;, &quot;01011&quot;, …
## $ never_mask     &lt;dbl&gt; 0.053, 0.083, 0.067, 0.020, 0.053, 0.031, 0.102, 0.152…
## $ rarely_mask    &lt;dbl&gt; 0.074, 0.059, 0.121, 0.034, 0.114, 0.040, 0.053, 0.108…
## $ sometimes_mask &lt;dbl&gt; 0.134, 0.098, 0.120, 0.096, 0.180, 0.144, 0.257, 0.130…
## $ freq_mask      &lt;dbl&gt; 0.295, 0.323, 0.201, 0.278, 0.194, 0.286, 0.137, 0.167…
## $ always_mask    &lt;dbl&gt; 0.444, 0.436, 0.491, 0.572, 0.459, 0.500, 0.451, 0.442…</code></pre>
<p>Cleaning <code>education</code>:</p>
<pre class="r"><code># discretized data -&gt; dominant type of education per county
education &lt;- education_untidy %&gt;% rename(fips = `FIPS Code`, 
    lessthanHS = `Less than a high school diploma, 2014-18`, 
    HSonly = `High school diploma only, 2014-18`, someCollegeorAssoc = `Some college or associate&#39;s degree, 2014-18`, 
    Bachorgreater = `Bachelor&#39;s degree or higher, 2014-18`) %&gt;% 
    select(fips, lessthanHS, HSonly, someCollegeorAssoc, Bachorgreater) %&gt;% 
    mutate(PrimaryEdAttained = case_when(lessthanHS &gt; HSonly &amp; 
        lessthanHS &gt; someCollegeorAssoc &amp; lessthanHS &gt; Bachorgreater ~ 
        &quot;lessthanHS&quot;, HSonly &gt; lessthanHS &amp; HSonly &gt; someCollegeorAssoc &amp; 
        HSonly &gt; Bachorgreater ~ &quot;HSonly&quot;, someCollegeorAssoc &gt; 
        lessthanHS &amp; someCollegeorAssoc &gt; HSonly &amp; someCollegeorAssoc &gt; 
        Bachorgreater ~ &quot;someCollegeorAssoc&quot;, Bachorgreater &gt; 
        lessthanHS &amp; Bachorgreater &gt; HSonly &amp; Bachorgreater &gt; 
        someCollegeorAssoc ~ &quot;Bachorgreater&quot;)) %&gt;% # removes rows for which there is no census data on
# educational attainment
na.omit() %&gt;% select(fips, PrimaryEdAttained, everything())

glimpse(education)</code></pre>
<pre><code>## Rows: 3,270
## Columns: 6
## $ fips               &lt;chr&gt; &quot;00000&quot;, &quot;01000&quot;, &quot;01001&quot;, &quot;01003&quot;, &quot;01005&quot;, &quot;0100…
## $ PrimaryEdAttained  &lt;chr&gt; &quot;Bachorgreater&quot;, &quot;HSonly&quot;, &quot;HSonly&quot;, &quot;Bachorgreate…
## $ lessthanHS         &lt;dbl&gt; 26948057, 470043, 4204, 14310, 4901, 2650, 7861, 1…
## $ HSonly             &lt;dbl&gt; 59265308, 1020172, 12119, 40579, 6486, 7471, 13489…
## $ someCollegeorAssoc &lt;dbl&gt; 63365655, 987148, 10552, 46025, 4566, 3846, 13267,…
## $ Bachorgreater      &lt;dbl&gt; 68867051, 822595, 10291, 46075, 2220, 1813, 5010, …</code></pre>
<p>Cleaning <code>popdata</code>:</p>
<pre class="r"><code>popdata &lt;- popdata_untidy %&gt;% rename(fips = FIPStxt, pop2019 = POP_ESTIMATE_2019, 
    int_mig = INTERNATIONAL_MIG_2019, dom_mig = DOMESTIC_MIG_2019, 
    net_mig = NET_MIG_2019) %&gt;% select(fips, pop2019, int_mig, 
    dom_mig, net_mig)

glimpse(popdata)</code></pre>
<pre><code>## Rows: 3,273
## Columns: 5
## $ fips    &lt;chr&gt; &quot;00000&quot;, &quot;01000&quot;, &quot;01001&quot;, &quot;01003&quot;, &quot;01005&quot;, &quot;01007&quot;, &quot;01009&quot;…
## $ pop2019 &lt;dbl&gt; 328239523, 4903185, 55869, 223234, 24686, 22394, 57826, 10101…
## $ int_mig &lt;dbl&gt; 595348, 2772, -16, 80, 13, 10, 6, -1, 18, 14, 6, -3, 35, -2, …
## $ dom_mig &lt;dbl&gt; 0, 9387, 270, 5297, -141, 31, 59, -72, -141, -475, -265, 306,…
## $ net_mig &lt;dbl&gt; 595348, 12159, 254, 5377, -128, 41, 65, -73, -123, -461, -259…</code></pre>
<p>Cleaning <code>povdata</code>:</p>
<pre class="r"><code>povdata &lt;- povdata_untidy %&gt;% rename(fips = FIPStxt, pctpov = PCTPOVALL_2018) %&gt;% 
    select(fips, pctpov)

glimpse(povdata)</code></pre>
<pre><code>## Rows: 3,193
## Columns: 2
## $ fips   &lt;chr&gt; &quot;00000&quot;, &quot;01000&quot;, &quot;01001&quot;, &quot;01003&quot;, &quot;01005&quot;, &quot;01007&quot;, &quot;01009&quot;,…
## $ pctpov &lt;dbl&gt; 13.1, 16.8, 13.8, 9.8, 30.9, 21.8, 13.2, 42.5, 24.5, 19.5, 18.…</code></pre>
<p>Cleaning <code>unemp</code>:</p>
<pre class="r"><code>unemp &lt;- unemp_untidy %&gt;% rename(fips = FIPStxt, emp = Employed_2019, 
    unemp = Unemployed_2019, med_inc = Median_Household_Income_2018) %&gt;% 
    select(fips, emp, unemp, med_inc)

glimpse(unemp)</code></pre>
<pre><code>## Rows: 3,275
## Columns: 4
## $ fips    &lt;chr&gt; &quot;00000&quot;, &quot;01000&quot;, &quot;01001&quot;, &quot;01003&quot;, &quot;01005&quot;, &quot;01007&quot;, &quot;01009&quot;…
## $ emp     &lt;dbl&gt; 157115247, 2174483, 25458, 94675, 8213, 8419, 24655, 4643, 89…
## $ unemp   &lt;dbl&gt; 5984808, 67264, 714, 2653, 324, 266, 676, 175, 338, 1635, 462…
## $ med_inc &lt;dbl&gt; 61937, 49881, 59338, 57588, 34382, 46064, 50412, 29267, 37365…</code></pre>
<hr />
</div>
<div id="joining-data" class="section level3">
<h3>Joining Data</h3>
<pre class="r"><code># join cvd and elect by county
cvdelect &lt;- cvd %&gt;% inner_join(elect, by = &quot;fips&quot;)

# join cvdelect and mask by county
cvdelectmask &lt;- cvdelect %&gt;% inner_join(mask, by = &quot;fips&quot;)

# join cvdelectmask and education by county
cvdelectmasked &lt;- cvdelectmask %&gt;% inner_join(education, by = &quot;fips&quot;)

# join cvdelectmasked and popdata by county
cvdelectmaskedpop &lt;- cvdelectmasked %&gt;% inner_join(popdata, by = &quot;fips&quot;)

# join cvdelectmaskedpop and povdata by county
cvdelectmaskedpoppov &lt;- cvdelectmaskedpop %&gt;% inner_join(povdata, 
    by = &quot;fips&quot;)

# join cvdelectmaskedpoppov and unemp by county
fulldata &lt;- cvdelectmaskedpoppov %&gt;% inner_join(unemp, by = &quot;fips&quot;) %&gt;% 
    na.omit()

glimpse(fulldata)</code></pre>
<pre><code>## Rows: 3,103
## Columns: 28
## $ date               &lt;date&gt; 2020-11-19, 2020-11-19, 2020-11-19, 2020-11-19, 2…
## $ county             &lt;chr&gt; &quot;Autauga&quot;, &quot;Baldwin&quot;, &quot;Barbour&quot;, &quot;Bibb&quot;, &quot;Blount&quot;,…
## $ state              &lt;chr&gt; &quot;Alabama&quot;, &quot;Alabama&quot;, &quot;Alabama&quot;, &quot;Alabama&quot;, &quot;Alaba…
## $ fips               &lt;chr&gt; &quot;01001&quot;, &quot;01003&quot;, &quot;01005&quot;, &quot;01007&quot;, &quot;01009&quot;, &quot;0101…
## $ cases              &lt;dbl&gt; 2554, 7933, 1145, 1011, 2683, 680, 1113, 5814, 164…
## $ deaths             &lt;dbl&gt; 39, 84, 10, 18, 35, 19, 41, 111, 48, 24, 36, 12, 1…
## $ votes              &lt;dbl&gt; 27639, 108945, 10457, 9573, 27459, 4603, 9466, 507…
## $ results_trumpd     &lt;dbl&gt; 19764, 83055, 5605, 7508, 24595, 1143, 5448, 34964…
## $ results_bidenj     &lt;dbl&gt; 7450, 24344, 4772, 1982, 2627, 3439, 3953, 15118, …
## $ trumpwin           &lt;dbl&gt; 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…
## $ never_mask         &lt;dbl&gt; 0.053, 0.083, 0.067, 0.020, 0.053, 0.031, 0.102, 0…
## $ rarely_mask        &lt;dbl&gt; 0.074, 0.059, 0.121, 0.034, 0.114, 0.040, 0.053, 0…
## $ sometimes_mask     &lt;dbl&gt; 0.134, 0.098, 0.120, 0.096, 0.180, 0.144, 0.257, 0…
## $ freq_mask          &lt;dbl&gt; 0.295, 0.323, 0.201, 0.278, 0.194, 0.286, 0.137, 0…
## $ always_mask        &lt;dbl&gt; 0.444, 0.436, 0.491, 0.572, 0.459, 0.500, 0.451, 0…
## $ PrimaryEdAttained  &lt;chr&gt; &quot;HSonly&quot;, &quot;Bachorgreater&quot;, &quot;HSonly&quot;, &quot;HSonly&quot;, &quot;HS…
## $ lessthanHS         &lt;dbl&gt; 4204, 14310, 4901, 2650, 7861, 1760, 2141, 12620, …
## $ HSonly             &lt;dbl&gt; 12119, 40579, 6486, 7471, 13489, 2817, 6091, 25653…
## $ someCollegeorAssoc &lt;dbl&gt; 10552, 46025, 4566, 3846, 13267, 1582, 3421, 26643…
## $ Bachorgreater      &lt;dbl&gt; 10291, 46075, 2220, 1813, 5010, 945, 2235, 14219, …
## $ pop2019            &lt;dbl&gt; 55869, 223234, 24686, 22394, 57826, 10101, 19448, …
## $ int_mig            &lt;dbl&gt; -16, 80, 13, 10, 6, -1, 18, 14, 6, -3, 35, -2, -5,…
## $ dom_mig            &lt;dbl&gt; 270, 5297, -141, 31, 59, -72, -141, -475, -265, 30…
## $ net_mig            &lt;dbl&gt; 254, 5377, -128, 41, 65, -73, -123, -461, -259, 30…
## $ pctpov             &lt;dbl&gt; 13.8, 9.8, 30.9, 21.8, 13.2, 42.5, 24.5, 19.5, 18.…
## $ emp                &lt;dbl&gt; 25458, 94675, 8213, 8419, 24655, 4643, 8925, 44574…
## $ unemp              &lt;dbl&gt; 714, 2653, 324, 266, 676, 175, 338, 1635, 462, 338…
## $ med_inc            &lt;dbl&gt; 59338, 57588, 34382, 46064, 50412, 29267, 37365, 4…</code></pre>
<hr />
</div>
<div id="manovaanova" class="section level3">
<h3>MANOVA/ANOVA</h3>
<pre class="r"><code># setting up for MANOVA assumptions
groups &lt;- fulldata$trumpwin
DVs &lt;- fulldata %&gt;% select(cases, deaths, always_mask, Bachorgreater, 
    net_mig, pctpov, unemp, med_inc, pop2019)

# Assumption 1: test for multivariate normality among each
# group (null H0: assumption met, DVs exhibit multivariate
# normality) p-values &lt; .05, assumption is not met, data is
# not normal
sapply(split(DVs, groups), mshapiro_test)</code></pre>
<pre><code>##           0            1           
## statistic 0.2731672    0.2939443   
## p.value   4.220809e-41 1.127073e-71</code></pre>
<pre class="r"><code># computing MANOVA for cases, deaths, always_mask, education
# attainment, net migration, % poverty, employment data,
# median income, and population vs trumpwin (1 = trumpwin, 0
# = bidenwin)
manova &lt;- manova(cbind(cases, deaths, always_mask, Bachorgreater, 
    net_mig, pctpov, unemp, med_inc, pop2019) ~ trumpwin, data = fulldata)
summary(manova)</code></pre>
<pre><code>##             Df  Pillai approx F num Df den Df    Pr(&gt;F)    
## trumpwin     1 0.31848   160.59      9   3093 &lt; 2.2e-16 ***
## Residuals 3101                                             
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># univariate ANOVA across groups
summary.aov(manova)</code></pre>
<pre><code>##  Response cases :
##               Df     Sum Sq    Mean Sq F value    Pr(&gt;F)    
## trumpwin       1 4.7155e+10 4.7155e+10  325.11 &lt; 2.2e-16 ***
## Residuals   3101 4.4978e+11 1.4504e+08                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
##  Response deaths :
##               Df    Sum Sq  Mean Sq F value    Pr(&gt;F)    
## trumpwin       1  25015933 25015933   350.8 &lt; 2.2e-16 ***
## Residuals   3101 221138881    71312                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
##  Response always_mask :
##               Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## trumpwin       1 13.339 13.3393  707.62 &lt; 2.2e-16 ***
## Residuals   3101 58.457  0.0189                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
##  Response Bachorgreater :
##               Df     Sum Sq    Mean Sq F value    Pr(&gt;F)    
## trumpwin       1 2.6072e+12 2.6072e+12  500.97 &lt; 2.2e-16 ***
## Residuals   3101 1.6139e+13 5.2044e+09                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
##  Response net_mig :
##               Df     Sum Sq  Mean Sq F value  Pr(&gt;F)  
## trumpwin       1 3.1563e+07 31562527  4.1292 0.04224 *
## Residuals   3101 2.3703e+10  7643795                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
##  Response pctpov :
##               Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## trumpwin       1   1305 1305.21  35.313 3.119e-09 ***
## Residuals   3101 114615   36.96                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
##  Response unemp :
##               Df     Sum Sq    Mean Sq F value    Pr(&gt;F)    
## trumpwin       1 1.3922e+10 1.3922e+10  374.87 &lt; 2.2e-16 ***
## Residuals   3101 1.1516e+11 3.7138e+07                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
##  Response med_inc :
##               Df     Sum Sq    Mean Sq F value    Pr(&gt;F)    
## trumpwin       1 2.2133e+10 2.2133e+10  120.29 &lt; 2.2e-16 ***
## Residuals   3101 5.7059e+11 1.8400e+08                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
##  Response pop2019 :
##               Df     Sum Sq    Mean Sq F value    Pr(&gt;F)    
## trumpwin       1 4.1059e+13 4.1059e+13  434.51 &lt; 2.2e-16 ***
## Residuals   3101 2.9303e+14 9.4496e+10                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># across the whole set of tests, the probability we have made
# at least one Type I error is: 1-P(no Type I) = 1-.95^x prob
# Type I error = .40126
1 - 0.95^10</code></pre>
<pre><code>## [1] 0.4012631</code></pre>
<pre class="r"><code># Bonferroni correction is: a_overall/# tests a&#39; = .005
0.05/10</code></pre>
<pre><code>## [1] 0.005</code></pre>
<p>Before getting into the test results, it should be noted that these data do not meet all of the MANOVA assumptions - specifically, the multivariate Shapiro-Wilk normality test shows the data does not exhibit multivariate normality. That being said, the results of this MANOVA test suggest that at least one response variable (COVID-19 <code>cases</code>/<code>deaths</code>, <code>always_mask</code>, education attainment (<code>Bachorgreater</code>), migration (<code>net_mig</code>), poverty percentages (<code>pctpov</code>), employment status (<code>unemp</code>), income (<code>med_inc</code>), and population (<code>pop2019</code>)) significantly differs between the groups of <code>trumpwin</code>. (F = 160.59, p &lt; 2.2e-16)</p>
<p>At this point, individual ANOVA tests are run for each response variable. In total, 10 hypothesis tests were completed, and the probability that we have made at least one Type I error is 0.40126. To keep the overall significance level at 0.05, an adjusted significance level, a’, of 0.005 should be utilized - this adjusted significance level was determined by the Bonferroni correction. No post-hoc tests were conducted here because we already know that the two groups differ based on the ANOVA tests alone; there are only two possible groups in the explanatory variable <code>trumpwin</code>!</p>
<p>Taking a closer look at the ANOVA tests for each individual response variable, <em>after adjusting for the probability of a Type I error</em>, all ANOVA tests except for the one between net migration (<code>net_mig</code>) and <code>trumpwin</code> are significant.</p>
<div id="covid-19-casesdeaths" class="section level4">
<h4>COVID-19 <code>cases</code>/<code>deaths</code></h4>
<ul>
<li><p>Holding all other response variables constant, the mean number of COVID-19 <code>cases</code> significantly differs between counties that Trump won and counties that Biden won. (F = 325.11, p &lt; 2.2e-16)</p></li>
<li><p>Holding all other response variables constant, the mean number of <code>deaths</code> to COVID-19 significantly differs between counties that Trump won and counties that Biden won. (F = 350.8, p &lt; 2.2e-16)</p></li>
</ul>
</div>
<div id="masking" class="section level4">
<h4>Masking</h4>
<ul>
<li>Holding all other response variables constant, the mean proportion of people who <code>always_mask</code> significantly differs between counties that Trump won and counties that Biden won. (F = 707.62, p &lt; 2.2e-16)</li>
</ul>
</div>
<div id="educational-attainment" class="section level4">
<h4>Educational attainment</h4>
<ul>
<li>Holding all other response variables constant, the mean number of people who report a bachelor’s degree or higher (<code>Bachorgreater</code>) as their highest level of education attained significantly differs between counties that Trump won and counties that Biden won. (F = 500.97, p &lt; 2.2e-16)</li>
</ul>
</div>
<div id="migration" class="section level4">
<h4>Migration</h4>
<ul>
<li>Holding all other response variables constant, the mean number of net migrations (<code>net_mig</code>) <strong>DOES NOT</strong> significantly differ between counties that Trump won and counties that Biden won. (F = 4.1292, p = .04224)</li>
</ul>
</div>
<div id="poverty" class="section level4">
<h4>Poverty</h4>
<ul>
<li>Holding all other response variables constant, the mean percentage of people of all ages in poverty (<code>pctpov</code>) significantly differs between counties that Trump won and counties that Biden won. (F = 35.313, p = 3.119e-09)</li>
</ul>
</div>
<div id="employment-status" class="section level4">
<h4>Employment Status</h4>
<ul>
<li>Holding all other response variables constant, the mean number of people who are unemployed (<code>unemp</code>) significantly differs between counties that Trump won and counties that Biden won. (F = 374.87, p &lt; 2.2e-16)</li>
</ul>
</div>
<div id="median-income" class="section level4">
<h4>Median Income</h4>
<ul>
<li>Holding all other response variables constant, the mean median household income (<code>med_inc</code>) significantly differs between counties that Trump won and counties that Biden won. (F = 120.29, p &lt; 2.2e-16)</li>
</ul>
</div>
<div id="population" class="section level4">
<h4>Population</h4>
<ul>
<li>Holding all other response variables constant, the mean population (<code>pop2019</code>) significantly differs between counties that Trump won and counties that Biden won. (F = 434.51, p &lt; 2.2e-16)</li>
</ul>
<hr />
</div>
</div>
<div id="randomization-test" class="section level3">
<h3>Randomization Test</h3>
<div id="calculating-mean-difference-in-the-proportion-of-always_mask-between-counties-trump-won-and-counties-biden-won" class="section level4">
<h4>Calculating mean difference in the proportion of <code>always_mask</code> between counties Trump won and counties Biden won</h4>
<pre class="r"><code># finding the test statistic: observed difference in means
# counties that Trump won have 17.435% fewer people who
# always mask compared to counties that Biden won
fulldata %&gt;% group_by(trumpwin) %&gt;% summarize(means = mean(always_mask)) %&gt;% 
    summarize(mean_diff = diff(means))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   mean_diff
##       &lt;dbl&gt;
## 1    -0.174</code></pre>
<pre class="r"><code># randomization test generating random distribution - makes
# no assumptions about the data
rand_dist &lt;- vector()
for (i in 1:5000) {
    new &lt;- data.frame(always_mask = sample(fulldata$always_mask), 
        trumpwin = fulldata$trumpwin)
    rand_dist[i] &lt;- mean(new[new$trumpwin == 1, ]$always_mask) - 
        mean(new[new$trumpwin == 0, ]$always_mask)
}

# plot visualizing null distribution and test statistic
{
    hist(rand_dist, main = &quot;Null Distribution&quot;, ylab = &quot;&quot;, xlim = c(-0.2, 
        0.2))
    abline(v = c(-0.17435, 0.17435), col = &quot;red&quot;)
}</code></pre>
<p><img src="/project/project2_files/figure-html/unnamed-chunk-11-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code># two-tailed p-value p-value = 0, reject the null hypothesis
mean(rand_dist &gt; 0.17435 | rand_dist &lt; -0.17435)</code></pre>
<pre><code>## [1] 0</code></pre>
<p>This randomization test simulated the mean difference in proportion of people who <code>always_mask</code> between counties Trump won and counties Biden won.</p>
<ul>
<li><p><span class="math inline">\(H_0: \mu_{maskTrump} - \mu_{maskBiden} = 0\)</span></p></li>
<li><p><span class="math inline">\(H_{\alpha}: \mu_{maskTrump} - \mu_{maskBiden} \neq 0\)</span></p></li>
</ul>
<p>The two-tailed p-value calculated represents the probability of observing a mean difference as extreme as the real mean difference under a randomization distribution. In this case, the two-tailed p-value of 0 tells us that there is a 0% chance of observing a mean difference in proportion of people who <code>always_mask</code> of 0.17435 under random conditions.</p>
<p>As such, we reject the null hypothesis that there is no difference/association in the mean proportions of people that <code>always_mask</code>s between counties Trump/Biden won. In other words, the true difference in means of people who <code>always_mask</code> between counties Trump won and counties Biden won is not equal to 0. This can be visualized nicely on the histogram of the null distribution; the vertical lines demonstrating the test statistic are extremely far away from the random distribution.</p>
<hr />
</div>
</div>
<div id="linear-regression" class="section level3">
<h3>Linear Regression</h3>
<div id="predicting-covid-19-deaths-from-trumpwin-and-number-of-people-unemployed" class="section level4">
<h4>Predicting COVID-19 <code>deaths</code> from <code>trumpwin</code> and number of people <code>unemp</code>loyed</h4>
<pre class="r"><code># mean centering unemp
fulldata$unemp_c &lt;- fulldata$unemp - mean(fulldata$unemp)

# linear regression
linearfit &lt;- lm(deaths ~ trumpwin * unemp_c, data = fulldata)
summary(linearfit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = deaths ~ trumpwin * unemp_c, data = fulldata)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1394.6   -13.8    -2.0     6.4  2447.3 
## 
## Coefficients:
##                    Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)       9.143e+01  5.965e+00  15.328  &lt; 2e-16 ***
## trumpwin         -2.518e+01  6.650e+00  -3.786 0.000156 ***
## unemp_c           3.844e-02  3.976e-04  96.684  &lt; 2e-16 ***
## trumpwin:unemp_c -3.082e-03  1.541e-03  -2.000 0.045586 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 130.4 on 3099 degrees of freedom
## Multiple R-squared:  0.786,  Adjusted R-squared:  0.7858 
## F-statistic:  3795 on 3 and 3099 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code># plot of linearfit
fulldata %&gt;% mutate(trumpwin = ifelse(trumpwin == 1, &quot;yes&quot;, &quot;no&quot;)) %&gt;% 
    ggplot(aes(x = unemp, y = deaths, color = trumpwin)) + geom_smooth(method = &quot;lm&quot;) + 
    geom_vline(xintercept = mean(fulldata$unemp), linetype = &quot;dashed&quot;) + 
    scale_x_log10() + labs(title = &quot;Plot of linear regression&quot;, 
    subtitle = &quot;Deaths vs Unemployment&quot;)</code></pre>
<p><img src="/project/project2_files/figure-html/unnamed-chunk-12-1.png" width="768" style="display: block; margin: auto;" />
Interpretations:</p>
<ul>
<li><p><code>(Intercept)</code>: <em>The predicted number of <code>deaths</code> to COVID-19 for counties Trump won and with average unemployment is 91.429 people.</em></p></li>
<li><p><code>trumpwin</code>: <em>For counties with average unemployment, there are 25.18 fewer <code>deaths</code> to COVID-19 in counties Trump won compared to counties Biden won.</em></p></li>
<li><p><code>unemp_c</code>: <em>On average, counties that Biden won show an increase of .038 <code>deaths</code> for every one more person unemployed.</em></p></li>
<li><p><code>trumpwin:unemp_c</code>: <em>The slope of unemployment on <code>deaths</code> to COVID-19 is .003 lower for counties Trump won compared to counties Biden won.</em></p></li>
</ul>
</div>
<div id="checking-assumptions-linearity-normality-homoscedasticity" class="section level4">
<h4>Checking assumptions: linearity, normality, homoscedasticity</h4>
<pre class="r"><code># checking linearity fails this assumption, the data is not
# linear
fulldata %&gt;% ggplot(aes(x = unemp, y = deaths)) + geom_point() + 
    scale_x_log10()</code></pre>
<p><img src="/project/project2_files/figure-html/unnamed-chunk-13-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code># checking normality with Kolmogorov-Smirnov test Ho: true
# distribution is normal p-value &lt; .05, we reject the null
# hypothesis fails this assumption, the data is not normal
ks.test(linearfit$residuals, &quot;pnorm&quot;, mean = 0, sd(linearfit$residuals))</code></pre>
<pre><code>## 
##  One-sample Kolmogorov-Smirnov test
## 
## data:  linearfit$residuals
## D = 0.32735, p-value &lt; 2.2e-16
## alternative hypothesis: two-sided</code></pre>
<pre class="r"><code># eyeballing homoscedasticity almost certainly not
# homoscedastic
plot(linearfit$fitted.values, linearfit$residuals)
abline(h = 0, col = &quot;red&quot;)</code></pre>
<p><img src="/project/project2_files/figure-html/unnamed-chunk-13-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code># checking homoscedasticity with Breusch-Pagan test Ho: the
# data is homoscedastic p-value &lt; .05, we reject the null
# hypothesis fails this assumption, the data is not
# homoscedastic
bptest(linearfit)</code></pre>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  linearfit
## BP = 772.68, df = 3, p-value &lt; 2.2e-16</code></pre>
<p>Based on the results of these tests and visualizations, this data is non-linear, not normally distributed, and not homoscedastic. As such, we’ll run a linear regression with robust and bootstrapped standard errors.</p>
<hr />
</div>
<div id="running-linear-regression-with-robust-standard-errors" class="section level4">
<h4>Running linear regression with robust standard errors</h4>
<pre class="r"><code># linear regression with robust SEs
coeftest(linearfit, vcov = vcovHC(linearfit))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                     Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)       91.4293192  22.0926867  4.1384 3.590e-05 ***
## trumpwin         -25.1805329  22.9069206 -1.0993    0.2717    
## unemp_c            0.0384448   0.0058189  6.6069 4.603e-11 ***
## trumpwin:unemp_c  -0.0030816   0.0080142 -0.3845    0.7006    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>After re-running the linear regression with robust standard errors, only the <code>(Intercept)</code> and <code>unemp</code>loyment estimates remain significant with p-values of 3.59e-05 and 4.603e-11, respectively. Based on the adjusted <span class="math inline">\(R^2\)</span> of the linear regression, approximately 78.6% of the variation in COVID-19 deaths can be explained by our model.</p>
</div>
<div id="running-linear-regression-with-bootstrapped-standard-errors" class="section level4">
<h4>Running linear regression with bootstrapped standard errors</h4>
<pre class="r"><code># bootstrap SEs by resampling rows
row_resample &lt;- replicate(5000, {
    boot_row &lt;- sample_frac(fulldata, replace = T)
    regression &lt;- lm(deaths ~ trumpwin * unemp_c, data = boot_row)
    coef(regression)
})

# SEs from original linear regression (normal SEs)
coeftest(linearfit)[, 1:2]</code></pre>
<pre><code>##                       Estimate   Std. Error
## (Intercept)       91.429319181 5.9649294694
## trumpwin         -25.180532905 6.6503007474
## unemp_c            0.038444819 0.0003976339
## trumpwin:unemp_c  -0.003081559 0.0015407672</code></pre>
<pre class="r"><code># SEs from second linear regression (robust SEs)
coeftest(linearfit, vcov = vcovHC(linearfit))[, 1:2]</code></pre>
<pre><code>##                       Estimate   Std. Error
## (Intercept)       91.429319181 22.092686725
## trumpwin         -25.180532905 22.906920586
## unemp_c            0.038444819  0.005818917
## trumpwin:unemp_c  -0.003081559  0.008014201</code></pre>
<pre class="r"><code># estimated SEs by resampling rows
row_resample %&gt;% t %&gt;% as.data.frame %&gt;% summarize_all(sd)</code></pre>
<pre><code>##   (Intercept) trumpwin     unemp_c trumpwin:unemp_c
## 1    15.37045 16.32481 0.004120472      0.006183857</code></pre>
<p>After re-running the linear regression with bootstrapped standard errors (determined by resampling rows), the <code>(Intercept)</code> and <code>unemp</code>loyment estimates remain significant, but we cannot conclusively say whether <code>trumpwin</code> and the interaction between <code>trumpwin</code> and <code>unemp</code> are significant based on our bootstrapped model.</p>
<p>As a rule, smaller standard errors result in smaller p-values/larger t-values and larger standard errors result in larger p-values/smaller t-values. With that in mind, we can make the following comparisons:</p>
<ul>
<li><p><em>model with normal SEs: smallest SEs out of the three models</em></p>
<ul>
<li>all estimates are significant; all p-values are &lt; .05</li>
</ul></li>
<li><p><em>model with robust SEs: largest SEs out of the three models</em></p>
<ul>
<li>the <code>(Intercept)</code> and <code>unemp</code>loyment estimates are significant; respective p-values are &lt; .05</li>
</ul></li>
<li><p><em>model with bootstrapped SEs: SEs are larger than the model with normal SEs, but smaller than the model with robust SEs</em></p>
<ul>
<li><p>the <code>(Intercept)</code> and <code>unemp</code>loyment estimates remain significant</p></li>
<li><p><code>trumpwin</code> and <code>trumpwin:unemp</code> may or may not be significant; the bootstrapped SEs inform us that the p-values should be less than those of the model with robust SEs, but we don’t know if they are small enough to be significant</p></li>
</ul></li>
</ul>
<hr />
</div>
</div>
<div id="logistic-regression-deathsalways_mask" class="section level3">
<h3>Logistic Regression <code>deaths</code>/<code>always_mask</code></h3>
<div id="predicting-trumpwin-from-deaths-and-always_mask-main-effects-only" class="section level4">
<h4>Predicting <code>trumpwin</code> from <code>deaths</code> and <code>always_mask</code>; main effects only</h4>
<pre class="r"><code># running logistic regression
logisticfit1 &lt;- glm(trumpwin ~ deaths + always_mask, data = fulldata, 
    family = &quot;binomial&quot;)
coeftest(logisticfit1)</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                Estimate  Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)  6.14342417  0.26784706  22.9363 &lt; 2.2e-16 ***
## deaths      -0.00426338  0.00049139  -8.6761 &lt; 2.2e-16 ***
## always_mask -7.49196585  0.44042335 -17.0108 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># exponentiate coefficients to get odds from log-odds
exp(coef(logisticfit1))</code></pre>
<pre><code>##  (Intercept)       deaths  always_mask 
## 4.656453e+02 9.957457e-01 5.575458e-04</code></pre>
<p>Interpretations:</p>
<ul>
<li><p><code>(Intercept)</code>: When 0% of people in a county <code>always_mask</code> and there are 0 <code>deaths</code> to COVID-19 in that county, the predicted odds that Trump wins is 465.645.</p></li>
<li><p><code>deaths</code>: When controlling for proportion of people who <code>always_mask</code> in each county, there is a significant effect of the number of <code>deaths</code> to COVID-19 on whether Trump or Biden won a county. Based on the exponentiated coefficient, we can determine that every additional death to COVID-19 in a county multiplies the odds Trump wins in that county by .9954. <em>In other words, the odds that Trump wins a county decrease by 0.46% for every additional death to COVID-19 in that county.</em></p></li>
<li><p><code>always_mask</code>: When controlling for the number of <code>deaths</code> to COVID-19, there is a significant effect of the proportion of people who <code>always_mask</code> on whether a county voted for Trump or Biden. Based on the exponentiated coefficient, we can determine that every unit increase in the proportion of people who always mask multiplies the odds Trump wins by .0006. <em>In other words, the odds that Trump wins a county decrease by a whopping 99.94% for every one unit increase in the proportion of people who always mask in that county.</em></p></li>
</ul>
</div>
<div id="computing-a-confusion-matrix-for-logisticfit1" class="section level4">
<h4>Computing a confusion matrix for <code>logisticfit1</code></h4>
<pre class="r"><code># getting predicted probabilities from logisticfit1
logisticfit1probs &lt;- predict(logisticfit1, type = &quot;response&quot;)

# getting predicted log-odds from logisticfit1
logisticfit1logit &lt;- predict(logisticfit1, type = &quot;link&quot;)

# using .5 as the threshold to predict a Trump win
table(predict = as.numeric(logisticfit1probs &gt; 0.5), truth = fulldata$trumpwin) %&gt;% 
    addmargins()</code></pre>
<pre><code>##        truth
## predict    0    1  Sum
##     0    170   63  233
##     1    359 2511 2870
##     Sum  529 2574 3103</code></pre>
<pre class="r"><code># Accuracy: (true pos + true neg)/total probability of
# predicting a correct win overall
(170 + 2511)/3103</code></pre>
<pre><code>## [1] 0.8640026</code></pre>
<pre class="r"><code># TPR (Sensitivity): true pos/total pos probability of
# predicting a Trump win in a county he actually won
2511/2574</code></pre>
<pre><code>## [1] 0.9755245</code></pre>
<pre class="r"><code># TNR (Specificity): true neg/total neg probability of
# predicting a Biden win in a county he actually won
170/529</code></pre>
<pre><code>## [1] 0.3213611</code></pre>
<pre class="r"><code># PPV (Precision): true pos/pred pos proportion of true Trump
# wins over those the model predicts he wins
2511/2870</code></pre>
<pre><code>## [1] 0.8749129</code></pre>
<pre class="r"><code># all values in one place using classification diagnostics
# function
class_diag(logisticfit1probs, fulldata$trumpwin)</code></pre>
<pre><code>##         acc      sens      spec       ppv        f1       auc
## 1 0.8640026 0.9755245 0.3213611 0.8749129 0.9224835 0.8391814</code></pre>
<ul>
<li><p><strong>Accuracy</strong>: Represents the probability of predicting a correct win overall. This model has an accuracy of .864, meaning 86.4% of its predictions were correct.</p>
<ul>
<li><span class="math inline">\(\frac{TruePos + TrueNeg}{Total}\)</span></li>
</ul></li>
<li><p><strong>TPR (Sensitivity)</strong>: Represents the probability of predicting a Trump win in a county Trump actually won. This model’s TPR is .9755, meaning 97.5% of the counties Trump won were correctly predicted.</p>
<ul>
<li><span class="math inline">\(\frac{TruePos}{TotalPos}\)</span></li>
</ul></li>
<li><p><strong>TNR (Specificity)</strong>: Represents the probability of predicting a Biden win (Trump loss) in a county Biden actually won. This model’s TNR is .321, meaning only 32.1% of the counties Biden won/Trump lost were correctly predicted.</p>
<ul>
<li><span class="math inline">\(\frac{TrueNeg}{TotalNeg}\)</span></li>
</ul></li>
<li><p><strong>PPV (Precision)</strong>: Represents the proportion of true Trump wins over those that the model predicts he wins. This model’s PPV is .875, meaning counties that Trump actually won represent 87.5% of those the model predicts for Trump.</p>
<ul>
<li><span class="math inline">\(\frac{TruePos}{PredPos}\)</span></li>
</ul></li>
<li><p><strong>AUC (area under the curve)</strong>: A way to quantify how well the model predicts outcomes overall - this quantification is based on a summarization of the trade-off between TPR and TNR, sensitivity and specificity, respectively. The AUC is a better alternative to accuracy, which can easily be duped! As a rule of thumb, the closer the AUC is to 1, the better the model predicts the outcome. This model’s AUC is .839, which falls into the “good” classification.</p></li>
</ul>
</div>
<div id="creating-a-density-plot-for-logisticfit1" class="section level4">
<h4>Creating a density plot for <code>logisticfit1</code></h4>
<pre class="r"><code>fulldata %&gt;% mutate(trumpwin = as.factor(trumpwin)) %&gt;% ggplot() + 
    geom_density(aes(logisticfit1logit, color = trumpwin, fill = trumpwin), 
        alpha = 0.4) + theme(legend.position = c(0.7, 0.85)) + 
    geom_vline(xintercept = 0) + labs(x = &quot;predictor (logit/log-odds)&quot;, 
    title = &quot;Density plot of log-odds&quot;, subtitle = &quot;Trump win = 1, Biden win = 0&quot;)</code></pre>
<p><img src="/project/project2_files/figure-html/unnamed-chunk-18-1.png" width="768" style="display: block; margin: auto;" /></p>
</div>
<div id="plotting-roc-curve-and-calculating-auc" class="section level4">
<h4>Plotting ROC curve and calculating AUC</h4>
<pre class="r"><code># ROC curve
ROCplot &lt;- ggplot(fulldata) + geom_roc(aes(d = trumpwin, m = logisticfit1probs), 
    n.cuts = 0)
ROCplot</code></pre>
<p><img src="/project/project2_files/figure-html/unnamed-chunk-19-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code># verifying AUC from above
calc_auc(ROCplot)</code></pre>
<pre><code>##   PANEL group       AUC
## 1     1    -1 0.8391994</code></pre>
<p>The ROC curve is a visualization of the trade-off between TPR and TNR and the AUC is just the area under the ROC curve! A perfect model will generate an ROC curve that is a 90 degree angle, leading first up the y-axis and then across the x-axis; this results in a computed AUC of 1. Re-calculating the AUC using the calc_auc function confirms this model’s AUC to be .839, which is “good” but not “great”.</p>
<center>
<p><strong>General AUC Interpretations</strong></p>
<p>0.9 - 1.0: Great</p>
<p>0.8 - 0.9: Good</p>
<p>0.7 - 0.8: Fair</p>
<p>0.6 - 0.7: Poor</p>
<p>0.5 - 0.6: Bad</p>
</center>
<hr />
</div>
</div>
<div id="logistic-regression-fulldata" class="section level3">
<h3>Logistic regression <code>fulldata</code></h3>
<div id="predicting-trumpwin-from-all-variables-main-effects-only" class="section level4">
<h4>Predicting <code>trumpwin</code> from all variables; main effects only</h4>
<pre class="r"><code># removing extraneous variables
fulldata2 &lt;- fulldata %&gt;% select(-date, -county, -state, -fips, 
    -results_trumpd, -results_bidenj, -unemp_c, -net_mig) %&gt;% 
    na.omit()
# running logistic regression
logisticfit2 &lt;- glm(trumpwin ~ ., data = fulldata2, family = &quot;binomial&quot;)
coeftest(logisticfit2)</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                        Estimate  Std. Error  z value  Pr(&gt;|z|)
## (Intercept)                         -7.6492e+01  1.0446e+02  -0.7323 0.4640095
## cases                                6.2225e-05  3.1820e-05   1.9555 0.0505196
## deaths                              -5.5368e-04  1.1620e-03  -0.4765 0.6337159
## votes                               -2.1669e-05  6.0114e-06  -3.6046 0.0003126
## never_mask                           8.6932e+01  1.0440e+02   0.8327 0.4050381
## rarely_mask                          8.5375e+01  1.0452e+02   0.8168 0.4140427
## sometimes_mask                       8.6587e+01  1.0440e+02   0.8294 0.4068821
## freq_mask                            8.2243e+01  1.0446e+02   0.7873 0.4311162
## always_mask                          7.8328e+01  1.0442e+02   0.7501 0.4532001
## PrimaryEdAttainedHSonly              2.5951e+00  2.4431e-01  10.6219 &lt; 2.2e-16
## PrimaryEdAttainedlessthanHS          2.5719e+00  5.4920e-01   4.6829 2.828e-06
## PrimaryEdAttainedsomeCollegeorAssoc  1.8338e+00  2.3696e-01   7.7391 1.001e-14
## lessthanHS                          -3.4716e-05  2.6921e-05  -1.2895 0.1972151
## HSonly                               4.0516e-05  1.4997e-05   2.7017 0.0068990
## someCollegeorAssoc                  -4.7440e-05  2.1282e-05  -2.2291 0.0258044
## Bachorgreater                        2.7628e-05  1.3174e-05   2.0971 0.0359818
## pop2019                              3.2988e-05  1.0671e-05   3.0914 0.0019922
## int_mig                             -9.3960e-04  3.8865e-04  -2.4176 0.0156231
## dom_mig                              3.1417e-04  5.1873e-05   6.0565 1.392e-09
## pctpov                              -2.0355e-01  1.7529e-02 -11.6121 &lt; 2.2e-16
## emp                                 -5.5712e-05  1.4203e-05  -3.9226 8.761e-05
## unemp                               -1.0670e-04  8.8216e-05  -1.2095 0.2264781
## med_inc                             -1.9275e-05  8.9025e-06  -2.1652 0.0303738
##                                        
## (Intercept)                            
## cases                               .  
## deaths                                 
## votes                               ***
## never_mask                             
## rarely_mask                            
## sometimes_mask                         
## freq_mask                              
## always_mask                            
## PrimaryEdAttainedHSonly             ***
## PrimaryEdAttainedlessthanHS         ***
## PrimaryEdAttainedsomeCollegeorAssoc ***
## lessthanHS                             
## HSonly                              ** 
## someCollegeorAssoc                  *  
## Bachorgreater                       *  
## pop2019                             ** 
## int_mig                             *  
## dom_mig                             ***
## pctpov                              ***
## emp                                 ***
## unemp                                  
## med_inc                             *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># exponentiate coefficients to odds from log-odds
exp(coef(logisticfit2))</code></pre>
<pre><code>##                         (Intercept)                               cases 
##                        6.027179e-34                        1.000062e+00 
##                              deaths                               votes 
##                        9.994465e-01                        9.999783e-01 
##                          never_mask                         rarely_mask 
##                        5.676395e+37                        1.196830e+37 
##                      sometimes_mask                           freq_mask 
##                        4.021780e+37                        5.220925e+35 
##                         always_mask             PrimaryEdAttainedHSonly 
##                        1.040521e+34                        1.339744e+01 
##         PrimaryEdAttainedlessthanHS PrimaryEdAttainedsomeCollegeorAssoc 
##                        1.309026e+01                        6.257880e+00 
##                          lessthanHS                              HSonly 
##                        9.999653e-01                        1.000041e+00 
##                  someCollegeorAssoc                       Bachorgreater 
##                        9.999526e-01                        1.000028e+00 
##                             pop2019                             int_mig 
##                        1.000033e+00                        9.990608e-01 
##                             dom_mig                              pctpov 
##                        1.000314e+00                        8.158278e-01 
##                                 emp                               unemp 
##                        9.999443e-01                        9.998933e-01 
##                             med_inc 
##                        9.999807e-01</code></pre>
</div>
<div id="computing-in-sample-classification-diagnostics" class="section level4">
<h4>Computing in-sample classification diagnostics</h4>
<pre class="r"><code># saving predicted probabilities
logisticfit2probs &lt;- predict(logisticfit2, type = &quot;response&quot;)

# running classification diagnostics (in-sample)
class_diag(logisticfit2probs, fulldata$trumpwin)</code></pre>
<pre><code>##         acc      sens      spec       ppv        f1       auc
## 1 0.9013858 0.9700855 0.5671078 0.9159941 0.9422642 0.9225129</code></pre>
<p><em>It’s important to note that these classification diagnostics represent only in-sample classifications and do not show how the model may predict observations out of sample.</em></p>
<ul>
<li><p><strong>Accuracy</strong>: Represents the probability of predicting a correct win overall. This model has an accuracy of .901, meaning 90.1% of its predictions were correct.</p>
<ul>
<li><span class="math inline">\(\frac{TruePos + TrueNeg}{Total}\)</span></li>
</ul></li>
<li><p><strong>TPR (Sensitivity)</strong>: Represents the probability of predicting a Trump win in a county Trump actually won. This model’s TPR is .9701, meaning 97.01% of the counties Trump won were correctly predicted.</p>
<ul>
<li><span class="math inline">\(\frac{TruePos}{TotalPos}\)</span></li>
</ul></li>
<li><p><strong>TNR (Specificity)</strong>: Represents the probability of predicting a Biden win (Trump loss) in a county Biden actually won. This model’s TNR is .567, meaning only 56.7% of the counties Biden won/Trump lost were correctly predicted.</p>
<ul>
<li><span class="math inline">\(\frac{TrueNeg}{TotalNeg}\)</span></li>
</ul></li>
<li><p><strong>PPV (Precision)</strong>: Represents the proportion of true Trump wins over those that the model predicts he wins. This model’s PPV is .916, meaning counties that Trump actually won represent 91.6% of those the model predicts for Trump.</p>
<ul>
<li><span class="math inline">\(\frac{TruePos}{PredPos}\)</span></li>
</ul></li>
<li><p><strong>AUC (area under the curve)</strong>: A way to quantify how well the model predicts outcomes overall - this quantification is based on a summarization of the trade-off between TPR and TNR, sensitivity and specificity, respectively. This model’s AUC is .923, which falls into the “great” classification.</p></li>
</ul>
<hr />
</div>
<div id="fold-cross-validation-on-logisticfit2" class="section level4">
<h4>10-fold cross-validation on <code>logisticfit2</code></h4>
<pre class="r"><code># setting number of folds
k = 10

# putting rows of dataset in random order
fd2CV &lt;- fulldata2 %&gt;% sample_frac

# creating fold labels
fd2folds &lt;- ntile(1:nrow(fulldata2), n = 10)

# empty diagnostics placeholder
fd2diags &lt;- NULL

# 10-fold CV
for (i in 1:k) {
    fd2train &lt;- fd2CV[fd2folds != i, ]
    fd2test &lt;- fd2CV[fd2folds == i, ]
    fd2truth &lt;- fd2test$trumpwin
    
    fd2fit &lt;- glm(trumpwin ~ ., data = fd2train, family = &quot;binomial&quot;)
    fd2probs &lt;- predict(fd2fit, newdata = fd2test, type = &quot;response&quot;)
    
    fd2diags &lt;- rbind(fd2diags, class_diag(fd2probs, fd2truth))
}

# finding average classification diagnostics out-of-sample
summarize_all(fd2diags, mean)</code></pre>
<pre><code>##         acc      sens      spec       ppv        f1       auc
## 1 0.8984836 0.9693726 0.5528735 0.9139296 0.9406603 0.9160466</code></pre>
<p><em>These classification diagnostics show how the previous model may predict observations out of sample. Across all diagnostics, the model is slightly worse at predicting out-of-sample, but not by a significant margin. Notably, the AUC only decreases from .923 to .916.</em></p>
<ul>
<li><p><strong>Accuracy</strong>: Out of sample, this model has an accuracy of .898, meaning 89.8% of its predictions were correct. (in sample: .901)</p>
<ul>
<li><span class="math inline">\(\frac{TruePos + TrueNeg}{Total}\)</span></li>
</ul></li>
<li><p><strong>TPR (Sensitivity)</strong>: Out of sample, this model’s TPR is .968, meaning 96.8% of the counties Trump won were correctly predicted. (in sample: .9701)</p>
<ul>
<li><span class="math inline">\(\frac{TruePos}{TotalPos}\)</span></li>
</ul></li>
<li><p><strong>TNR (Specificity)</strong>: Out of sample, this model’s TNR is .560, meaning only 56.0% of the counties Biden won/Trump lost were correctly predicted. (in sample, .567)</p>
<ul>
<li><span class="math inline">\(\frac{TrueNeg}{TotalNeg}\)</span></li>
</ul></li>
<li><p><strong>PPV (Precision)</strong>: Out of sample, this model’s PPV is .915, meaning counties that Trump actually won represent 91.5% of those the model predicts for Trump. (in sample: .916)</p>
<ul>
<li><span class="math inline">\(\frac{TruePos}{PredPos}\)</span></li>
</ul></li>
<li><p><strong>AUC (area under the curve)</strong>: Out of sample, this model’s AUC is .916, which still falls into the “great” classification. (in sample: .923)</p></li>
</ul>
<hr />
</div>
<div id="lasso-to-choose-a-simpler-model" class="section level4">
<h4>LASSO to choose a simpler model</h4>
<div id="may-lead-to-better-predictions-out-of-sample" class="section level5">
<h5>May lead to better predictions out-of-sample</h5>
<pre class="r"><code># scaled fd2 predictors
fd2_preds &lt;- model.matrix(trumpwin ~ ., data = fulldata2)[, -1] %&gt;% 
    scale

# trumpwin
fd2_response &lt;- as.matrix(fulldata2$trumpwin)

# CV to select lambda + 1se
cv &lt;- cv.glmnet(fd2_preds, fd2_response, family = &quot;binomial&quot;)

# lasso
lasso_fit &lt;- glmnet(fd2_preds, fd2_response, family = &quot;binomial&quot;, 
    lambda = cv$lambda.1se)
coef(lasso_fit)</code></pre>
<pre><code>## 23 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                                              s0
## (Intercept)                          2.20432120
## cases                                .         
## deaths                               .         
## votes                               -0.84236731
## never_mask                           0.08446452
## rarely_mask                          0.06641440
## sometimes_mask                       0.11297011
## freq_mask                            .         
## always_mask                         -0.73615631
## PrimaryEdAttainedHSonly              0.90813224
## PrimaryEdAttainedlessthanHS          0.10086609
## PrimaryEdAttainedsomeCollegeorAssoc  0.46281936
## lessthanHS                           .         
## HSonly                               .         
## someCollegeorAssoc                   .         
## Bachorgreater                        .         
## pop2019                              .         
## int_mig                              .         
## dom_mig                              0.30292537
## pctpov                              -0.79803340
## emp                                  .         
## unemp                                .         
## med_inc                             -0.13878301</code></pre>
<p>The non-zero coefficient estimates of the LASSO regression (variables to be retained) are those of votes, never_mask, rarely_mask, sometimes_mask, always_mask, certain levels of primary education level attained (HSonly, lessthanHS, someCollegeorAssoc), dom_mig (domestic migration), pctpov (percent in poverty), and med_inc (median income). Utilizing these variables to create a model should result in improved predictions out-of-sample. To verify this, we’ll run another 10-fold CV using only the variables LASSO suggests and compare the AUCs between each model.</p>
</div>
</div>
<div id="fold-cross-validation-on-lasso-model" class="section level4">
<h4>10-fold cross-validation on LASSO model</h4>
<pre class="r"><code># creating dummies for significant primary education levels
fulldata2dummies &lt;- fulldata2 %&gt;% mutate(PEdHSonly = ifelse(fulldata2$PrimaryEdAttained == 
    &quot;HSonly&quot;, 1, 0), PEdlessthanHS = ifelse(fulldata2$PrimaryEdAttained == 
    &quot;lessthanHS&quot;, 1, 0), PEdsomeCollegeorAssoc = ifelse(fulldata2$PrimaryEdAttained == 
    &quot;someCollegeorAssoc&quot;, 1, 0))

# shuffling rows of dataset
lassodata &lt;- fulldata2dummies %&gt;% sample_frac

# creating fold labels
lassofolds &lt;- ntile(1:nrow(lassodata), n = 10)

# creating empty placeholder
lassodiags &lt;- NULL

# 10-fold CV
k = 10
for (i in 1:k) {
    trainlasso &lt;- lassodata[lassofolds != i, ]
    testlasso &lt;- lassodata[lassofolds == i, ]
    truthlasso &lt;- testlasso$trumpwin
    
    lassofit &lt;- glm(trumpwin ~ votes + never_mask + rarely_mask + 
        sometimes_mask + always_mask + PEdHSonly + PEdlessthanHS + 
        PEdsomeCollegeorAssoc + dom_mig + pctpov + med_inc, data = trainlasso, 
        family = &quot;binomial&quot;)
    lassoprobs &lt;- predict(lassofit, newdata = testlasso, type = &quot;response&quot;)
    
    lassodiags &lt;- rbind(lassodiags, class_diag(lassoprobs, truthlasso))
}

# summarizing results
summarize_all(lassodiags, mean)</code></pre>
<pre><code>##         acc      sens      spec       ppv        f1      auc
## 1 0.8965398 0.9667179 0.5610574 0.9136639 0.9392221 0.915796</code></pre>
<p><em>These classification diagnostics are pretty interesting. Across all diagnostics, the model is slightly worse the original logistic regression at predicting both in- and out-of-sample, but not by a significant margin. Theoretically, because of its more conservative estimate, the LASSO model should result in improved out-of-sample predictions compared to that of the full model; while this is indeed the case here, the improvement is only marginal. Notably, when compared to the out-of-sample AUC of the full model, this AUC only improves from .9156 to .9158.</em></p>
<ul>
<li><p><strong>Accuracy</strong>: The LASSO model has an accuracy of .8956 out of sample, meaning 89.56% of its predictions were correct. This is lower than that of both the in- and out-of-sample full model predictions, which had accuracies of .901 and .898, respectively.</p>
<ul>
<li><span class="math inline">\(\frac{TruePos + TrueNeg}{Total}\)</span></li>
</ul></li>
<li><p><strong>TPR (Sensitivity)</strong>: The LASSO model has a TPR of .9675 out of sample, meaning 96.75% of the counties Trump won were correctly predicted. This is lower than that of both the in- and out-of-sample full model predictions, which had TPRs of .9676 and .9701, respectively.</p>
<ul>
<li><span class="math inline">\(\frac{TruePos}{TotalPos}\)</span></li>
</ul></li>
<li><p><strong>TNR (Specificity)</strong>: The LASSO model has a TNR of .5471 out of sample, meaning 54.71% of the counties Biden won/Trump lost were correctly predicted. This is lower than that of both the in- and out-of-sample full model predictions, which had TNRs of .560 and .567, respectively.</p>
<ul>
<li><span class="math inline">\(\frac{TrueNeg}{TotalNeg}\)</span></li>
</ul></li>
<li><p><strong>PPV (Precision)</strong>: The LASSO model has a PPV of .912 out of sample, meaning counties that Trump actually won represent 91.2% of those the model predicts for Trump. This is lower than that of both the in- and out-of-sample full model predictions, which had PPVs of .915 and .916, respectively.</p>
<ul>
<li><span class="math inline">\(\frac{TruePos}{PredPos}\)</span></li>
</ul></li>
<li><p><strong>AUC (area under the curve)</strong>: The LASSO model has an AUC of .9158 out of sample. This is very slightly improved compared to the out-of-sample AUC of the full model (.9156). Compared to the in-sample AUC of the full model, the LASSO model’s AUC is lower, but this is to be expected; out-of-sample predictions are rarely as good as those in-sample. That being said, all three AUCs (from the full model and LASSO model) are “great”.</p></li>
</ul>
<hr />
</div>
</div>
<div id="links-to-datasets" class="section level3">
<h3>Links to Datasets</h3>
<ul>
<li><p>COVID-19 by county: <a href="https://github.com/nytimes/covid-19-data/blob/master/us-counties.csv"><code>cvd_untidy</code></a></p></li>
<li><p>2020 presidential election results by county: <a href="https://github.com/favstats/USElection2020-NYT-Results"><code>elect</code></a></p></li>
<li><p>Mask use by county: <a href="https://github.com/nytimes/covid-19-data/tree/master/mask-use"><code>mask</code></a></p></li>
<li><p>Educational attainment by county: <a href="https://www.ers.usda.gov/data-products/county-level-data-sets/download-data/"><code>education</code></a></p></li>
<li><p>Population data by county: <a href="https://www.ers.usda.gov/data-products/county-level-data-sets/download-data/"><code>popdata</code></a></p></li>
<li><p>Poverty metrics by county: <a href="https://www.ers.usda.gov/data-products/county-level-data-sets/download-data/"><code>povdata</code></a></p></li>
<li><p>Unemployment data by county: <a href="https://www.ers.usda.gov/data-products/county-level-data-sets/download-data/"><code>unemp</code></a></p></li>
</ul>
<pre><code>## R version 4.0.3 (2020-10-10)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Big Sur 10.16
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] glmnet_4.0-2      Matrix_1.2-18     plotROC_2.2.1     sandwich_3.0-0   
##  [5] lmtest_0.9-38     zoo_1.8-8         rstatix_0.6.0     lubridate_1.7.9.2
##  [9] forcats_0.5.0     stringr_1.4.0     dplyr_1.0.2       purrr_0.3.4      
## [13] readr_1.4.0       tidyr_1.1.2       tibble_3.0.4      ggplot2_3.3.2    
## [17] tidyverse_1.3.0   knitr_1.30       
## 
## loaded via a namespace (and not attached):
##  [1] httr_1.4.2        jsonlite_1.7.1    splines_4.0.3     foreach_1.5.1    
##  [5] carData_3.0-4     modelr_0.1.8      assertthat_0.2.1  cellranger_1.1.0 
##  [9] yaml_2.2.1        pillar_1.4.7      backports_1.2.0   lattice_0.20-41  
## [13] glue_1.4.2        digest_0.6.27     rvest_0.3.6       colorspace_2.0-0 
## [17] plyr_1.8.6        htmltools_0.5.0   pkgconfig_2.0.3   broom_0.7.2      
## [21] haven_2.3.1       bookdown_0.21     scales_1.1.1      openxlsx_4.2.3   
## [25] rio_0.5.16        mgcv_1.8-33       farver_2.0.3      generics_0.1.0   
## [29] car_3.0-10        ellipsis_0.3.1    withr_2.3.0       cli_2.2.0        
## [33] survival_3.2-7    magrittr_2.0.1    crayon_1.3.4      readxl_1.3.1     
## [37] evaluate_0.14     fs_1.5.0          fansi_0.4.1       nlme_3.1-150     
## [41] xml2_1.3.2        foreign_0.8-80    blogdown_0.20     tools_4.0.3      
## [45] data.table_1.13.2 hms_0.5.3         formatR_1.7       lifecycle_0.2.0  
## [49] munsell_0.5.0     reprex_0.3.0      zip_2.1.1         compiler_4.0.3   
## [53] rlang_0.4.9       grid_4.0.3        iterators_1.0.13  rstudioapi_0.13  
## [57] labeling_0.4.2    rmarkdown_2.5     gtable_0.3.0      codetools_0.2-18 
## [61] abind_1.4-5       DBI_1.1.0         curl_4.3          R6_2.5.0         
## [65] utf8_1.1.4        shape_1.4.5       stringi_1.5.3     Rcpp_1.0.5       
## [69] vctrs_0.3.5       dbplyr_2.0.0      tidyselect_1.1.0  xfun_0.19</code></pre>
<pre><code>## [1] &quot;2021-06-03 23:06:09 CDT&quot;</code></pre>
<pre><code>##                                                                                           sysname 
##                                                                                          &quot;Darwin&quot; 
##                                                                                           release 
##                                                                                          &quot;20.3.0&quot; 
##                                                                                           version 
## &quot;Darwin Kernel Version 20.3.0: Thu Jan 21 00:07:06 PST 2021; root:xnu-7195.81.3~1/RELEASE_X86_64&quot; 
##                                                                                          nodename 
##                                                                        &quot;Bowens-MacBook-Pro.local&quot; 
##                                                                                           machine 
##                                                                                          &quot;x86_64&quot; 
##                                                                                             login 
##                                                                                            &quot;root&quot; 
##                                                                                              user 
##                                                                                           &quot;Bowen&quot; 
##                                                                                    effective_user 
##                                                                                           &quot;Bowen&quot;</code></pre>
</div>

            
        <hr>         <div class="related-posts">
                <h5>Related Posts</h5>
                
              </div> 
            </div>
          </div>

   <hr>  <div class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">

    (function() {
      
      
      if (window.location.hostname == "localhost")
        return;

      var disqus_shortname = '';
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div> 
        </div>
      </div>
    </div>

    
    <footer>
  <div id="footer">
    <div class="container">
      <p class="text-muted">&copy; All rights reserved. Powered by <a href="https://gohugo.io/">Hugo</a> and
      <a href="http://www.github.com/nurlansu/hugo-sustain/">sustain</a> with ♥</p>
    </div>
  </div>
</footer>
<div class="footer"></div>


<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="/js/docs.min.js"></script>
<script src="/js/main.js"></script>

<script src="/js/ie10-viewport-bug-workaround.js"></script>


    
  </body>
</html>
